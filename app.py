import io
import json
import datetime as dt
from pathlib import Path

import pandas as pd
import streamlit as st


st.set_page_config(page_title="ì†¡ì¥ ìë™í™”", page_icon="ğŸ“¦", layout="wide")

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
CONFIG_FILE = Path("config.json")


def load_config():
    """ì„¤ì • íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if CONFIG_FILE.exists():
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_config(config: dict):
    """ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"ì„¤ì • ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return False


def get_openai_api_key():
    """ì €ì¥ëœ OpenAI API í‚¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    config = load_config()
    return config.get("openai_api_key", "")


def save_openai_api_key(api_key: str):
    """OpenAI API í‚¤ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    config = load_config()
    config["openai_api_key"] = api_key
    return save_config(config)


def test_openai_api(api_key: str, message: str):
    """OpenAI APIë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. (Responses API)"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        response = client.responses.create(
            model="gpt-5.1-2025-11-13",
            input=[
                {"role": "system", "content": "You are a helpful assistant. Please respond in Korean."},
                {"role": "user", "content": message}
            ],
            max_output_tokens=500
        )

        return {"success": True, "message": response.output_text}

    except Exception as e:
        return {"success": False, "message": f"API ì˜¤ë¥˜: {str(e)}"}

def parse_naver_option(option_str: str) -> dict:
    """ë„¤ì´ë²„ ì˜µì…˜ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    result = {
        "ë³´ë‚´ì‹œëŠ”ë¶„": "",
        "ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸": "",
        "ê³¼ì¼ì„ ë¬¼ì˜µì…˜": "",
        "í¬ë¦¬ìŠ¤íƒˆë³´ìê¸°": ""
    }

    if pd.isna(option_str):
        return result

    # " / "ë¡œ ë¶„ë¦¬
    parts = str(option_str).split(" / ")

    for part in parts:
        if ":" in part:
            key, value = part.split(":", 1)
            key = key.strip()
            value = value.strip()

            if "ë³´ë‚´ì‹œëŠ” ë¶„" in key:
                result["ë³´ë‚´ì‹œëŠ”ë¶„"] = value
            elif "ë„ì°© í¬ë§ ë‚ ì§œ" in key or "ë„ì°©í¬ë§ë‚ ì§œ" in key:
                result["ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸"] = value
            elif "ê³¼ì¼ ì„ ë¬¼ ì˜µì…˜" in key or "ê³¼ì¼ì„ ë¬¼ì˜µì…˜" in key:
                result["ê³¼ì¼ì„ ë¬¼ì˜µì…˜"] = value
            elif "í¬ë¦¬ìŠ¤íƒˆ ë³´ìê¸°" in key:
                result["í¬ë¦¬ìŠ¤íƒˆë³´ìê¸°"] = value

    return result


def normalize_dates_batch_with_ai(api_key: str, date_list: list) -> dict:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚ ì§œ ë°°ì—´ì„ ì¼ê´„ ì •ê·œí™”í•©ë‹ˆë‹¤. (Responses API ê¸°ë°˜, ì˜¤ë¥˜ ì•ˆì „ ì²˜ë¦¬ í¬í•¨)"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        dates_json = json.dumps(date_list, ensure_ascii=False)

        prompt = f"""
ë‹¤ìŒ JSON ë°°ì—´ì˜ ê° ë‚ ì§œ í…ìŠ¤íŠ¸ë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
"ìµœëŒ€í•œ ë¹¨ë¦¬", "ë¹ ë¥¸ë°°ì†¡" ë“± ë‚ ì§œê°€ ì•„ë‹Œ ê²½ìš° "ë¹ ë¥¸ë°°ì†¡"ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.
ë‚ ì§œ ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•˜ë‹¤ê³  íŒë‹¨ë ë•ŒëŠ” ì¸í’‹ì— ìˆëŠ” ë‚ ì§œ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ë³€í™˜í•˜ì„¸ìš”. 
ë³€í™˜í•˜ëŠ” ë‚ ì§œë“¤ì€ ë¹„ìŠ·í•œ ì‹œì ì…ë‹ˆë‹¤.

ì…ë ¥: {dates_json}

ì¶œë ¥ì€ ë°˜ë“œì‹œ "ì›ë³¸": "ë³€í™˜ê²°ê³¼" í˜•íƒœì˜ JSON ê°ì²´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
ì˜ˆì‹œ: {{"9ì›”30ì¼": "2024-09-30", "10/1": "2024-10-01", "ìµœëŒ€í•œ ë¹¨ë¦¬": "ë¹ ë¥¸ë°°ì†¡"}}
"""

        response = client.responses.create(
            model="gpt-5.1-2025-11-13",
            input=prompt,
            max_output_tokens=1000,
        )

        result_text = (response.output_text or "").strip()

        # 1) ì¶œë ¥ì´ ë¹„ì—ˆìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
        if not result_text:
            return {date: "ì˜¤ë¥˜: ë¹ˆ ì‘ë‹µ" for date in date_list}

        # 2) ì½”ë“œë¸”ë¡ ì œê±°
        if result_text.startswith("```"):
            parts = result_text.split("```")
            if len(parts) >= 2:
                result_text = parts[1]
            result_text = result_text.replace("json", "").strip()

        # 3) JSONë§Œ ì¶”ì¶œ (ì•ë’¤ í…ìŠ¤íŠ¸ ì œê±°)
        #    â†’ { ... } ë§Œ ì°¾ì•„ì„œ parse
        import re
        json_match = re.search(r"\{.*\}", result_text, re.DOTALL)
        if json_match:
            result_text = json_match.group(0).strip()
        else:
            return {date: "ì˜¤ë¥˜: JSON ì¶œë ¥ ì•„ë‹˜" for date in date_list}

        # 4) JSON íŒŒì‹±
        try:
            return json.loads(result_text)
        except Exception:
            return {date: f"ì˜¤ë¥˜: JSON íŒŒì‹± ì‹¤íŒ¨: {result_text}" for date in date_list}

    except Exception as e:
        return {date: f"ì˜¤ë¥˜: {str(e)}" for date in date_list}


def create_naver_intermediate_table(df: pd.DataFrame, api_key: str) -> pd.DataFrame:
    """ë„¤ì´ë²„ ë¡œìš°ë°ì´í„°ë¡œë¶€í„° ì¤‘ê°„ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # ì˜µì…˜ì •ë³´ íŒŒì‹±
    parsed_options = df["ì˜µì…˜ì •ë³´"].apply(parse_naver_option)
    parsed_df = pd.DataFrame(parsed_options.tolist())

    # ì¤‘ê°„ í…Œì´ë¸” ìƒì„±
    intermediate = pd.DataFrame({
        "ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸": df["ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸"],
        "ìˆ˜ì·¨ì¸ëª…": df["ìˆ˜ì·¨ì¸ëª…"],
        "ìˆ˜ì·¨ì¸ì—°ë½ì²˜1": df["ìˆ˜ì·¨ì¸ì—°ë½ì²˜1"],
        "í†µí•©ë°°ì†¡ì§€": df["í†µí•©ë°°ì†¡ì§€"],
        "ë°°ì†¡ë©”ì„¸ì§€": df["ë°°ì†¡ë©”ì„¸ì§€"],
        "ìˆ˜ëŸ‰": df["ìˆ˜ëŸ‰"],
        "ì˜µì…˜ê´€ë¦¬ì½”ë“œ": df["ì˜µì…˜ê´€ë¦¬ì½”ë“œ"],
        "ë³´ë‚´ì‹œëŠ”ë¶„": parsed_df["ë³´ë‚´ì‹œëŠ”ë¶„"],
        "ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸": parsed_df["ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸"],
        "ë„ì°©í¬ë§ë‚ ì§œ_ì •ê·œí™”": "",  # AIë¡œ ì±„ìš¸ ì˜ˆì •
        "ê³¼ì¼ì„ ë¬¼ì˜µì…˜": parsed_df["ê³¼ì¼ì„ ë¬¼ì˜µì…˜"],
    })

    return intermediate


def normalize_dates_batch(intermediate_df: pd.DataFrame, api_key: str, progress_callback=None, debug_callback=None) -> pd.DataFrame:
    """ì¤‘ê°„ í…Œì´ë¸”ì˜ ë‚ ì§œë¥¼ ì¼ê´„ ì •ê·œí™”í•©ë‹ˆë‹¤. (ë°°ì¹˜ ì²˜ë¦¬)"""
    result_df = intermediate_df.copy()

    # ìœ ë‹ˆí¬í•œ ë‚ ì§œ ë¬¸ìì—´ë§Œ ì¶”ì¶œ
    unique_dates = result_df["ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸"].dropna().unique().tolist()

    if not unique_dates:
        return result_df

    # ë””ë²„ê·¸: ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜ í‘œì‹œ
    if debug_callback:
        debug_callback("info", f"ğŸ“Š ì¶”ì¶œëœ ìœ ë‹ˆí¬ ë‚ ì§œ: {len(unique_dates)}ê°œ")
        debug_callback("unique_dates", unique_dates[:10])  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ

    # ë‚ ì§œ ë³€í™˜ ê²°ê³¼ ìºì‹œ
    date_mapping = {}

    # 100ê°œì”© ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
    batch_size = 30
    total_batches = (len(unique_dates) + batch_size - 1) // batch_size

    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, len(unique_dates))
        batch = unique_dates[start_idx:end_idx]

        # ë””ë²„ê·¸: ë°°ì¹˜ ì •ë³´ í‘œì‹œ
        if debug_callback:
            debug_callback("batch_start", f"ë°°ì¹˜ {batch_idx + 1}/{total_batches} - {len(batch)}ê°œ ë‚ ì§œ ì²˜ë¦¬ ì¤‘...")

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ AI í˜¸ì¶œ (ë”•ì…”ë„ˆë¦¬ ë°˜í™˜)
        batch_mapping = normalize_dates_batch_with_ai(api_key, batch)

        # ë””ë²„ê·¸: AI ì‘ë‹µ í‘œì‹œ
        if debug_callback:
            debug_callback("batch_result", {"batch_idx": batch_idx + 1, "mapping": batch_mapping})

        # ê²°ê³¼ë¥¼ ì „ì²´ ë§¤í•‘ì— ë³‘í•©
        date_mapping.update(batch_mapping)

        if progress_callback:
            progress_callback(batch_idx + 1, total_batches)

    # ë§¤í•‘ ì ìš©
    result_df["ë„ì°©í¬ë§ë‚ ì§œ_ì •ê·œí™”"] = result_df["ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸"].map(date_mapping).fillna("")

    return result_df


def generate_cj_orders_by_date(intermediate_df: pd.DataFrame, defaults: dict[str, str]) -> dict:
    """ë‚ ì§œë³„ë¡œ CJ ë°œì£¼ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
    grouped = intermediate_df.groupby("ë„ì°©í¬ë§ë‚ ì§œ_ì •ê·œí™”")

    results = {}

    for date, group in grouped:
        # CJ ë°œì£¼ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        qty = pd.to_numeric(group["ìˆ˜ëŸ‰"], errors="coerce").fillna(0).astype(int)
        item_name = group["ë³´ë‚´ì‹œëŠ”ë¶„"].fillna("OOO").astype(str) + "ë“œë¦¼ " + group["ì˜µì…˜ê´€ë¦¬ì½”ë“œ"].fillna("").astype(str)

        cj_df = pd.DataFrame({
            "ë³´ë‚´ëŠ”ë¶„ì„±ëª…": defaults["name"],
            "ë³´ë‚´ëŠ”ë¶„ì „í™”ë²ˆí˜¸": defaults["phone"],
            "ë³´ë‚´ëŠ”ë¶„ì£¼ì†Œ(ì „ì²´,ë¶„í• )": defaults["address"],
            "ìš´ì„êµ¬ë¶„": "ì‹ ìš©",
            "ë°•ìŠ¤íƒ€ì…": "ê·¹ì†Œ",
            "ê¸°ë³¸ìš´ì„": qty * 2200,
            "ê³ ê°ì£¼ë¬¸ë²ˆí˜¸": group["ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸"],
            "í’ˆëª©ëª…": item_name,
            "ìˆ˜ëŸ‰": qty,
            "ìˆ˜ì·¨ì¸ì´ë¦„": group["ìˆ˜ì·¨ì¸ëª…"],
            "ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸": group["ìˆ˜ì·¨ì¸ì—°ë½ì²˜1"],
            "ìˆ˜ì·¨ì¸ ì£¼ì†Œ": group["í†µí•©ë°°ì†¡ì§€"],
            "ë°°ì†¡ë©”ì„¸ì§€": group["ë°°ì†¡ë©”ì„¸ì§€"],
        })

        # ì—‘ì…€ íŒŒì¼ë¡œ ë³€í™˜
        buf = io.BytesIO()
        cj_df.to_excel(buf, index=False)
        buf.seek(0)

        results[date] = {
            "df": cj_df,
            "data": buf.getvalue(),
            "count": len(cj_df)
        }

    return results


# Lightweight custom styling for a clean, card-like UI
st.markdown(
    """
    <style>
    :root {
        --bg: #eef2f8;
        --text: #1f2d3d;
    }
    body { background: radial-gradient(circle at 20% 20%, #f7f9ff, var(--bg)); color: var(--text); }
    .card { border-radius: 18px; padding: 18px 20px; background: white;
            box-shadow: 0 10px 30px rgba(0,0,0,0.06);
            transition: transform .15s ease, box-shadow .15s ease; }
    .card:hover { transform: translateY(-4px); box-shadow: 0 14px 36px rgba(0,0,0,0.12); }
    .choice { display: grid; grid-template-columns: repeat(auto-fit, minmax(260px, 1fr)); gap: 16px; }

    /* Base button styling */
    button[kind] {
        background: #f2f4f8;
        border: 1px solid #dfe4ed;
        color: var(--text);
        border-radius: 12px;
        box-shadow: 0 10px 24px rgba(0, 0, 0, 0.06);
        transition: all 0.15s ease;
    }
    button[kind]:hover {
        background: #ffffff;
        border-color: #cbd4e2;
        transform: translateY(-1px);
        box-shadow: 0 12px 26px rgba(0, 0, 0, 0.08);
    }
    button:focus { outline: none !important; box-shadow: 0 0 0 3px rgba(66, 99, 235, 0.2); }

    /* Landing buttons (grey base, hover to white) */
    button[aria-label="ğŸšš CJ ë°œì£¼ì„œ ë§Œë“¤ê¸°"],
    button[aria-label="ğŸ“‘ ëŒ€ëŸ‰ë“±ë¡ íŒŒì¼ ë§Œë“¤ê¸°"] {
        max-width: 280px;
        width: 100%;
    }

    /* Channel buttons: pastel per brand */
    button[aria-label="ğŸŸ¢ ë„¤ì´ë²„"] {
        background: #d8f3dc;
        border-color: #b7e4c7;
        color: #2b7a0b;
        max-width: 240px;
        width: 100%;
    }
    button[aria-label="ğŸŸ¢ ë„¤ì´ë²„"]:hover {
        background: #e8f7ee;
        border-color: #a3d9b2;
        color: #246908;
    }
    button[aria-label="ğŸŸ  ì¿ íŒ¡"] {
        background: #dbeafe;
        border-color: #b6d4ff;
        color: #1f4b99;
        max-width: 240px;
        width: 100%;
    }
    button[aria-label="ğŸŸ  ì¿ íŒ¡"]:hover {
        background: #eef4ff;
        border-color: #a3c5ff;
        color: #153f85;
    }

    /* Settings icon button - clean and minimal */
    .settings-btn button {
        background: transparent !important;
        border: none !important;
        box-shadow: none !important;
        padding: 8px !important;
        font-size: 24px !important;
        transition: all 0.2s ease !important;
        color: #6b7280 !important;
    }
    .settings-btn button:hover {
        background: transparent !important;
        transform: rotate(90deg) scale(1.1) !important;
        color: #1f2937 !important;
        box-shadow: none !important;
    }
    .settings-btn button:active {
        transform: rotate(90deg) scale(0.95) !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# íƒ€ì´í‹€ê³¼ ì„¤ì • ë²„íŠ¼
col1, col2 = st.columns([10, 1])
with col1:
    st.title("ğŸ“¦ ì†¡ì¥ ìë™í™”")
with col2:
    st.write("")  # ì—¬ë°± ì¶”ê°€
    st.markdown('<div class="settings-btn">', unsafe_allow_html=True)
    if st.button("âš™ï¸", help="ì„¤ì •", key="settings_btn"):
        st.session_state.show_settings = True
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)

st.caption("CJ ë°œì£¼ì„œ Â· ëŒ€ëŸ‰ë“±ë¡ íŒŒì¼ ìë™ ìƒì„±")

if "step" not in st.session_state:
    st.session_state.step = "landing"
if "job" not in st.session_state:
    st.session_state.job = None
if "channel" not in st.session_state:
    st.session_state.channel = None
if "coupang_cj_result" not in st.session_state:
    st.session_state.coupang_cj_result = None
if "coupang_bulk_result" not in st.session_state:
    st.session_state.coupang_bulk_result = None
if "last_uploaded_name" not in st.session_state:
    st.session_state.last_uploaded_name = None
if "last_bulk_names" not in st.session_state:
    st.session_state.last_bulk_names = (None, None)
if "show_settings" not in st.session_state:
    st.session_state.show_settings = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "naver_cj_result" not in st.session_state:
    st.session_state.naver_cj_result = None
if "last_naver_uploaded_name" not in st.session_state:
    st.session_state.last_naver_uploaded_name = None
if "naver_intermediate_table" not in st.session_state:
    st.session_state.naver_intermediate_table = None
if "naver_raw_data" not in st.session_state:
    st.session_state.naver_raw_data = None
if "naver_workflow_step" not in st.session_state:
    st.session_state.naver_workflow_step = "upload"  # upload -> parse -> review -> generate


def reset():
    st.session_state.step = "landing"
    st.session_state.job = None
    st.session_state.channel = None
    st.rerun()


def section_heading(title: str, subtitle: str | None = None):
    st.subheader(title)
    if subtitle:
        st.caption(subtitle)


def go(step: str, job: str | None = None, channel: str | None = None):
    if job is not None:
        st.session_state.job = job
    if channel is not None:
        st.session_state.channel = channel
    st.session_state.step = step
    st.rerun()


def get_sender_defaults():
    """Sender defaults read from example CJ ë°œì£¼ì„œ if available, else fall back values."""
    example_path = Path("output/example/coupang/ì¿ íŒ¡ CJ ë°œì£¼ì„œ.xlsx")
    defaults = {
        "name": "ê³¼ì¼ì„ ë¬¼ì€ ì²­ê³¼ì˜¥",
        "phone": "010-8238-0368",
        "address": "ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬ ì„œì´ˆëŒ€ë¡œ15ê¸¸ 13-4 (ë°©ë°°ë™) 102í˜¸",
    }
    if example_path.exists():
        try:
            sample = pd.read_excel(example_path)
            defaults["name"] = str(sample.loc[0, "ë³´ë‚´ëŠ”ë¶„ì„±ëª…"])
            defaults["phone"] = str(sample.loc[0, "ë³´ë‚´ëŠ”ë¶„ì „í™”ë²ˆí˜¸"])
            defaults["address"] = str(sample.loc[0, "ë³´ë‚´ëŠ”ë¶„ì£¼ì†Œ(ì „ì²´,ë¶„í• )"])
        except Exception:
            pass
    return defaults


def get_coupang_bulk_columns():
    """Column order for ì¿ íŒ¡ ëŒ€ëŸ‰ë“±ë¡, prefer reading from example file."""
    example_path = Path("output/example/coupang/ì¿ íŒ¡ ëŒ€ëŸ‰ë“±ë¡.xlsx")
    fallback = [
        "ë²ˆí˜¸",
        "ë¬¶ìŒë°°ì†¡ë²ˆí˜¸",
        "ì£¼ë¬¸ë²ˆí˜¸",
        "íƒë°°ì‚¬",
        "ìš´ì†¡ì¥ë²ˆí˜¸",
        "ë¶„ë¦¬ë°°ì†¡ Y/N",
        "ë¶„ë¦¬ë°°ì†¡ ì¶œê³ ì˜ˆì •ì¼",
        "ì£¼ë¬¸ì‹œ ì¶œê³ ì˜ˆì •ì¼",
        "ì¶œê³ ì¼(ë°œì†¡ì¼)",
        "ì£¼ë¬¸ì¼",
        "ë“±ë¡ìƒí’ˆëª…",
        "ë“±ë¡ì˜µì…˜ëª…",
        "ë…¸ì¶œìƒí’ˆëª…(ì˜µì…˜ëª…)",
        "ë…¸ì¶œìƒí’ˆID",
        "ì˜µì…˜ID",
        "ìµœì´ˆë“±ë¡ì˜µì…˜ëª…",
        "ì—…ì²´ìƒí’ˆì½”ë“œ",
        "ë°”ì½”ë“œ",
        "ê²°ì œì•¡",
        "ë°°ì†¡ë¹„êµ¬ë¶„",
        "ë°°ì†¡ë¹„",
        "ë„ì„œì‚°ê°„ ì¶”ê°€ë°°ì†¡ë¹„",
        "êµ¬ë§¤ìˆ˜(ìˆ˜ëŸ‰)",
        "ì˜µì…˜íŒë§¤ê°€(íŒë§¤ë‹¨ê°€)",
        "êµ¬ë§¤ì",
        "êµ¬ë§¤ìì „í™”ë²ˆí˜¸",
        "ìˆ˜ì·¨ì¸ì´ë¦„",
        "ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸",
        "ìš°í¸ë²ˆí˜¸",
        "ìˆ˜ì·¨ì¸ ì£¼ì†Œ",
        "ë°°ì†¡ë©”ì„¸ì§€",
        "ìƒí’ˆë³„ ì¶”ê°€ë©”ì‹œì§€",
        "ì£¼ë¬¸ì ì¶”ê°€ë©”ì‹œì§€",
        "ë°°ì†¡ì™„ë£Œì¼",
        "êµ¬ë§¤í™•ì •ì¼ì",
        "ê°œì¸í†µê´€ë²ˆí˜¸(PCCC)",
        "í†µê´€ìš©êµ¬ë§¤ìì „í™”ë²ˆí˜¸",
        "ê¸°íƒ€",
        "ê²°ì œìœ„ì¹˜",
    ]
    if example_path.exists():
        try:
            cols = list(pd.read_excel(example_path, nrows=0).columns)
            if cols:
                return cols
        except Exception:
            pass
    return fallback


def clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Strip whitespace from column names to avoid merge mismatches."""
    return df.rename(columns=lambda c: str(c).strip())


def build_coupang_cj(df: pd.DataFrame, defaults: dict[str, str]) -> pd.DataFrame:
    """Transform Coupang raw data into CJ ë°œì£¼ì„œ format."""
    required_cols = [
        "ìˆ˜ì·¨ì¸ì´ë¦„",
        "ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸",
        "ìˆ˜ì·¨ì¸ ì£¼ì†Œ",
        "ë°°ì†¡ë©”ì„¸ì§€",
        "êµ¬ë§¤ìˆ˜(ìˆ˜ëŸ‰)",
        "êµ¬ë§¤ì",
        "ì—…ì²´ìƒí’ˆì½”ë“œ",
        "ì£¼ë¬¸ë²ˆí˜¸",
    ]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"ëˆ„ë½ëœ í•„ìˆ˜ ì»¬ëŸ¼: {', '.join(missing)}")

    def normalize_order(x):
        if pd.isna(x):
            return ""
        if isinstance(x, float):
            return str(int(x))
        if isinstance(x, int):
            return str(x)
        s = str(x).strip()
        if s.endswith(".0") and s.replace(".", "", 1).isdigit():
            try:
                return str(int(float(s)))
            except Exception:
                return s
        return s

    qty = pd.to_numeric(df["êµ¬ë§¤ìˆ˜(ìˆ˜ëŸ‰)"], errors="coerce").fillna(0).astype(int)
    item_name = (
        df["êµ¬ë§¤ì"].fillna("").astype(str)
        + "ë“œë¦¼ "
        + df["ì—…ì²´ìƒí’ˆì½”ë“œ"].fillna("").astype(str)
    )
    order_no = df["ì£¼ë¬¸ë²ˆí˜¸"].apply(normalize_order)

    output = pd.DataFrame(
        {
            "ë³´ë‚´ëŠ”ë¶„ì„±ëª…": defaults["name"],
            "ë³´ë‚´ëŠ”ë¶„ì „í™”ë²ˆí˜¸": defaults["phone"],
            "ë³´ë‚´ëŠ”ë¶„ì£¼ì†Œ(ì „ì²´,ë¶„í• )": defaults["address"],
            "ìš´ì„êµ¬ë¶„": "ì‹ ìš©",
            "ë°•ìŠ¤íƒ€ì…": "ê·¹ì†Œ",
            "ê¸°ë³¸ìš´ì„": qty * 2200,
            "ê³ ê°ì£¼ë¬¸ë²ˆí˜¸": order_no,
            "í’ˆëª©ëª…": item_name,
            "ìˆ˜ëŸ‰": qty,
            "ìˆ˜ì·¨ì¸ì´ë¦„": df["ìˆ˜ì·¨ì¸ì´ë¦„"],
            "ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸": df["ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸"],
            "ìˆ˜ì·¨ì¸ ì£¼ì†Œ": df["ìˆ˜ì·¨ì¸ ì£¼ì†Œ"],
            "ë°°ì†¡ë©”ì„¸ì§€": df["ë°°ì†¡ë©”ì„¸ì§€"],
        }
    )
    return output


def build_naver_cj(df: pd.DataFrame, defaults: dict[str, str]) -> pd.DataFrame:
    """Transform Naver raw data into CJ ë°œì£¼ì„œ format."""
    required_cols = [
        "ìˆ˜ì·¨ì¸ëª…",
        "ìˆ˜ì·¨ì¸ì—°ë½ì²˜1",
        "í†µí•©ë°°ì†¡ì§€",
        "ë°°ì†¡ë©”ì„¸ì§€",
        "ìˆ˜ëŸ‰",
        "ì˜µì…˜ê´€ë¦¬ì½”ë“œ",
        "ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸",
    ]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"ëˆ„ë½ëœ í•„ìˆ˜ ì»¬ëŸ¼: {', '.join(missing)}")

    def normalize_order(x):
        if pd.isna(x):
            return ""
        if isinstance(x, float):
            return str(int(x))
        if isinstance(x, int):
            return str(x)
        s = str(x).strip()
        if s.endswith(".0") and s.replace(".", "", 1).isdigit():
            try:
                return str(int(float(s)))
            except Exception:
                return s
        return s

    qty = pd.to_numeric(df["ìˆ˜ëŸ‰"], errors="coerce").fillna(0).astype(int)
    # ë„¤ì´ë²„ëŠ” "OOOë“œë¦¼ {ì˜µì…˜ê´€ë¦¬ì½”ë“œ}" í˜•ì‹
    item_name = "OOOë“œë¦¼ " + df["ì˜µì…˜ê´€ë¦¬ì½”ë“œ"].fillna("").astype(str)
    order_no = df["ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸"].apply(normalize_order)

    output = pd.DataFrame(
        {
            "ë³´ë‚´ëŠ”ë¶„ì„±ëª…": defaults["name"],
            "ë³´ë‚´ëŠ”ë¶„ì „í™”ë²ˆí˜¸": defaults["phone"],
            "ë³´ë‚´ëŠ”ë¶„ì£¼ì†Œ(ì „ì²´,ë¶„í• )": defaults["address"],
            "ìš´ì„êµ¬ë¶„": "ì‹ ìš©",
            "ë°•ìŠ¤íƒ€ì…": "ê·¹ì†Œ",
            "ê¸°ë³¸ìš´ì„": qty * 2200,
            "ê³ ê°ì£¼ë¬¸ë²ˆí˜¸": order_no,
            "í’ˆëª©ëª…": item_name,
            "ìˆ˜ëŸ‰": qty,
            "ìˆ˜ì·¨ì¸ì´ë¦„": df["ìˆ˜ì·¨ì¸ëª…"],
            "ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸": df["ìˆ˜ì·¨ì¸ì—°ë½ì²˜1"],
            "ìˆ˜ì·¨ì¸ ì£¼ì†Œ": df["í†µí•©ë°°ì†¡ì§€"],
            "ë°°ì†¡ë©”ì„¸ì§€": df["ë°°ì†¡ë©”ì„¸ì§€"],
        }
    )
    return output


def render_coupang_cj():
    st.markdown("**ì¿ íŒ¡ ë¡œìš°ë°ì´í„° ì—…ë¡œë“œ**")
    uploaded = st.file_uploader(
        "ì¿ íŒ¡ ë¡œìš°ë°ì´í„° ì—‘ì…€ íŒŒì¼ (.xlsx)", type=["xlsx"], accept_multiple_files=False
    )

    # Reset previous result if new file uploaded
    if uploaded and uploaded.name != st.session_state.last_uploaded_name:
        st.session_state.coupang_cj_result = None
        st.session_state.last_uploaded_name = uploaded.name

    if uploaded:
        df = pd.read_excel(uploaded)
        st.caption("ì—…ë¡œë“œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 5í–‰)")
        st.dataframe(df.head(5), width="stretch")

        if st.button("ì‘ì—… ì‹¤í–‰", type="primary"):
            try:
                defaults = get_sender_defaults()
                sorted_df = df.sort_values("ì—…ì²´ìƒí’ˆì½”ë“œ").reset_index(drop=True)
                result_df = build_coupang_cj(sorted_df, defaults)
                buf = io.BytesIO()
                result_df.to_excel(buf, index=False)
                buf.seek(0)
                filename = f"ì¿ íŒ¡_CJë°œì£¼ì„œ_{dt.datetime.now():%y%m%d}.xlsx"
                st.session_state.coupang_cj_result = {
                    "df": result_df,
                    "data": buf.getvalue(),
                    "name": filename,
                }
                st.success(f"ì‘ì—… ì™„ë£Œ: {filename}")
            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    result = st.session_state.get("coupang_cj_result")
    if result:
        st.markdown("---")
        st.markdown("**ì‘ì—… ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10í–‰)**")
        st.dataframe(result["df"].head(10), width="stretch")
        st.download_button(
            "ë‹¤ìš´ë¡œë“œ: ì¿ íŒ¡ CJ ë°œì£¼ì„œ",
            data=result["data"],
            file_name=result["name"],
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary",
        )


def render_naver_cj():
    """ë„¤ì´ë²„ CJ ë°œì£¼ì„œ ìƒì„± ì›Œí¬í”Œë¡œìš° (ì¤‘ê°„ í…Œì´ë¸” í¬í•¨)"""

    # API í‚¤ í™•ì¸
    api_key = get_openai_api_key()
    if not api_key:
        st.warning("âš ï¸ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        return

    # ì›Œí¬í”Œë¡œìš° ìƒíƒœ í‘œì‹œ
    steps = ["1ï¸âƒ£ íŒŒì¼ ì—…ë¡œë“œ", "2ï¸âƒ£ ë°ì´í„° ê²€ìˆ˜", "3ï¸âƒ£ CJ ë°œì£¼ì„œ ìƒì„±"]
    current_step = st.session_state.naver_workflow_step

    if current_step == "upload":
        step_idx = 0
    elif current_step == "review":
        step_idx = 1
    else:  # generate
        step_idx = 2

    st.markdown(f"**ì§„í–‰ ë‹¨ê³„:** {' â†’ '.join([f'**{s}**' if i == step_idx else s for i, s in enumerate(steps)])}")
    st.markdown("---")

    # STEP 1: íŒŒì¼ ì—…ë¡œë“œ
    if current_step == "upload":
        st.markdown("### 1ï¸âƒ£ ë„¤ì´ë²„ ë¡œìš°ë°ì´í„° ì—…ë¡œë“œ")
        st.caption("ë„¤ì´ë²„ ì—‘ì…€ íŒŒì¼ì€ ì²« í–‰ì— ì•ˆë‚´ë¬¸ì´ ìˆìœ¼ë¯€ë¡œ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")

        uploaded = st.file_uploader(
            "ë„¤ì´ë²„ ë¡œìš°ë°ì´í„° ì—‘ì…€ íŒŒì¼ (.xlsx)",
            type=["xlsx"],
            accept_multiple_files=False,
            key="naver_cj_uploader"
        )

        if uploaded:
            # ë„¤ì´ë²„ëŠ” header=1ë¡œ ì½ì–´ì•¼ í•¨ (ì²« í–‰ì´ ì•ˆë‚´ë¬¸)
            df = pd.read_excel(uploaded, header=1)
            st.session_state.naver_raw_data = df

            st.caption(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ì£¼ë¬¸")
            st.dataframe(df.head(5), width="stretch")

            if st.button("ë‹¤ìŒ ë‹¨ê³„: ë°ì´í„° íŒŒì‹± ë° ê²€ìˆ˜", type="primary"):
                with st.spinner("ì˜µì…˜ì •ë³´ íŒŒì‹± ì¤‘..."):
                    # ì¤‘ê°„ í…Œì´ë¸” ìƒì„±
                    intermediate = create_naver_intermediate_table(df, api_key)
                    st.session_state.naver_intermediate_table = intermediate
                    st.session_state.naver_workflow_step = "review"
                    st.rerun()

    # STEP 2: ë°ì´í„° ê²€ìˆ˜
    elif current_step == "review":
        st.markdown("### 2ï¸âƒ£ ë°ì´í„° ê²€ìˆ˜ ë° ìˆ˜ì •")
        st.caption("AIê°€ ë‚ ì§œë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤. ê²€ìˆ˜ í›„ í•„ìš” ì‹œ ìˆ˜ì •í•˜ì„¸ìš”.")

        intermediate = st.session_state.naver_intermediate_table

        # AI ë‚ ì§œ ì •ê·œí™” ë²„íŠ¼
        if intermediate["ë„ì°©í¬ë§ë‚ ì§œ_ì •ê·œí™”"].iloc[0] == "":
            if st.button("ğŸ¤– AIë¡œ ë‚ ì§œ ìë™ ë³€í™˜", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                debug_container = st.expander("ğŸ” ìƒì„¸ ë¡œê·¸ (ë””ë²„ê¹…)", expanded=True)

                debug_logs = []

                def update_progress(current, total):
                    progress = current / total
                    progress_bar.progress(progress)
                    status_text.text(f"ë‚ ì§œ ë³€í™˜ ì¤‘... (ë°°ì¹˜ {current}/{total})")

                def debug_log(log_type, data):
                    if log_type == "info":
                        debug_logs.append(("info", data))
                        with debug_container:
                            st.info(data)
                    elif log_type == "unique_dates":
                        debug_logs.append(("unique", data))
                        with debug_container:
                            st.write("**ğŸ“‹ ìœ ë‹ˆí¬ ë‚ ì§œ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):**")
                            st.write(data)
                    elif log_type == "batch_start":
                        debug_logs.append(("batch_start", data))
                        with debug_container:
                            st.write(f"â³ {data}")
                    elif log_type == "batch_result":
                        debug_logs.append(("result", data))
                        with debug_container:
                            st.write(f"**âœ… ë°°ì¹˜ {data['batch_idx']} ê²°ê³¼:**")
                            st.json(data["mapping"])

                with st.spinner("AIë¡œ ë‚ ì§œ ì •ê·œí™” ì¤‘..."):
                    intermediate = normalize_dates_batch(intermediate, api_key, update_progress, debug_log)
                    st.session_state.naver_intermediate_table = intermediate

                progress_bar.empty()
                status_text.empty()
                st.success("âœ… ë‚ ì§œ ë³€í™˜ ì™„ë£Œ!")
                st.rerun()
        else:
            st.success("âœ… ë‚ ì§œ ë³€í™˜ ì™„ë£Œ")

        # ë°ì´í„° í¸ì§‘ê¸°
        st.markdown("**ì¤‘ê°„ í…Œì´ë¸” (ìˆ˜ì • ê°€ëŠ¥)**")
        st.caption("ë‚ ì§œê°€ ì˜ëª» ë³€í™˜ëœ ê²½ìš° ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (YYYY-MM-DD í˜•ì‹)")

        edited_df = st.data_editor(
            intermediate,
            use_container_width=True,
            num_rows="fixed",
            disabled=["ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸", "ìˆ˜ì·¨ì¸ëª…", "ìˆ˜ì·¨ì¸ì—°ë½ì²˜1", "í†µí•©ë°°ì†¡ì§€", "ë°°ì†¡ë©”ì„¸ì§€", "ìˆ˜ëŸ‰", "ì˜µì…˜ê´€ë¦¬ì½”ë“œ", "ë„ì°©í¬ë§ë‚ ì§œ_ì›ë³¸"],
            key="naver_intermediate_editor"
        )

        st.session_state.naver_intermediate_table = edited_df

        # ë‚ ì§œë³„ í†µê³„
        st.markdown("---")
        st.markdown("**ğŸ“Š ë‚ ì§œë³„ ì£¼ë¬¸ í†µê³„**")
        date_counts = edited_df["ë„ì°©í¬ë§ë‚ ì§œ_ì •ê·œí™”"].value_counts().sort_index()
        date_counts_df = date_counts.reset_index()
        date_counts_df.columns = ["ë‚ ì§œ", "ì£¼ë¬¸ ìˆ˜"]
        st.dataframe(date_counts_df, width="stretch")

        # ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("â† ì²˜ìŒë¶€í„° ë‹¤ì‹œ"):
                st.session_state.naver_workflow_step = "upload"
                st.session_state.naver_intermediate_table = None
                st.session_state.naver_raw_data = None
                st.rerun()
        with col2:
            if st.button("ë‹¤ìŒ ë‹¨ê³„: CJ ë°œì£¼ì„œ ìƒì„± â†’", type="primary"):
                st.session_state.naver_workflow_step = "generate"
                st.rerun()

    # STEP 3: CJ ë°œì£¼ì„œ ìƒì„±
    elif current_step == "generate":
        st.markdown("### 3ï¸âƒ£ ë‚ ì§œë³„ CJ ë°œì£¼ì„œ ìƒì„±")

        intermediate = st.session_state.naver_intermediate_table

        if st.button("ğŸ“¦ CJ ë°œì£¼ì„œ ìƒì„±", type="primary"):
            with st.spinner("CJ ë°œì£¼ì„œ ìƒì„± ì¤‘..."):
                defaults = get_sender_defaults()
                results = generate_cj_orders_by_date(intermediate, defaults)
                st.session_state.naver_cj_result = results
                st.success(f"âœ… {len(results)}ê°œ ë‚ ì§œë³„ ë°œì£¼ì„œ ìƒì„± ì™„ë£Œ!")

        # ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ
        results = st.session_state.get("naver_cj_result")
        if results:
            st.markdown("---")
            st.markdown("**ğŸ“¥ ë‹¤ìš´ë¡œë“œ**")

            for date, result in sorted(results.items()):
                with st.expander(f"ğŸ“… {date} ({result['count']}ê±´)"):
                    st.dataframe(result["df"].head(10), width="stretch")
                    st.download_button(
                        f"ë‹¤ìš´ë¡œë“œ: {date}",
                        data=result["data"],
                        file_name=f"ë„¤ì´ë²„_CJë°œì£¼ì„œ_{date}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download_{date}"
                    )

        # ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë²„íŠ¼
        st.markdown("---")
        if st.button("â† ì²˜ìŒë¶€í„° ë‹¤ì‹œ"):
            st.session_state.naver_workflow_step = "upload"
            st.session_state.naver_intermediate_table = None
            st.session_state.naver_raw_data = None
            st.session_state.naver_cj_result = None
            st.rerun()


def build_coupang_bulk(raw_df: pd.DataFrame, cj_df: pd.DataFrame) -> pd.DataFrame:
    """Merge Coupang raw data with CJ ì ‘ìˆ˜ ìƒì„¸ë‚´ì—­ to produce bulk upload."""

    raw_df = clean_columns(raw_df)
    cj_df = clean_columns(cj_df)

    def normalize_number(x):
        if pd.isna(x):
            return ""
        if isinstance(x, float):
            return str(int(x))
        if isinstance(x, int):
            return str(x)
        s = str(x).strip()
        if s.endswith(".0") and s.replace(".", "", 1).isdigit():
            try:
                return str(int(float(s)))
            except Exception:
                return s
        return s

    raw_df = raw_df.copy()
    cj_df = cj_df.copy()

    raw_df["__key"] = raw_df["ì£¼ë¬¸ë²ˆí˜¸"].apply(normalize_number)
    key_col = "ê³ ê°ì£¼ë¬¸ë²ˆí˜¸" if "ê³ ê°ì£¼ë¬¸ë²ˆí˜¸" in cj_df.columns else "ì£¼ë¬¸ë²ˆí˜¸"
    cj_df["__key"] = cj_df[key_col].apply(normalize_number)

    merged = raw_df.merge(
        cj_df[["__key", "ìš´ì†¡ì¥ë²ˆí˜¸", "ì§‘í™”ì˜ˆì •ì¼ì"]],
        on="__key",
        how="left",
        suffixes=("", "_cj"),
    )

    # ìµœì¢… ìš´ì†¡ì¥ë²ˆí˜¸: CJ íŒŒì¼ ê°’ ìš°ì„ , ì—†ìœ¼ë©´ ë¡œìš°ë°ì´í„° ê°’
    if "ìš´ì†¡ì¥ë²ˆí˜¸_cj" in merged:
        merged["__ìš´ì†¡ì¥ë²ˆí˜¸"] = merged["ìš´ì†¡ì¥ë²ˆí˜¸_cj"].fillna(merged.get("ìš´ì†¡ì¥ë²ˆí˜¸"))
    else:
        merged["__ìš´ì†¡ì¥ë²ˆí˜¸"] = merged.get("ìš´ì†¡ì¥ë²ˆí˜¸")
    merged["__ìš´ì†¡ì¥ë²ˆí˜¸"] = merged["__ìš´ì†¡ì¥ë²ˆí˜¸"].apply(normalize_number)

    def pick(col, default=""):
        return merged[col] if col in merged.columns else default

    output_cols = get_coupang_bulk_columns()

    # Map values: mostly raw, plus CJ ìš´ì†¡ì¥ë²ˆí˜¸, ì¶œê³ ì¼(ë°œì†¡ì¼)=ì§‘í™”ì˜ˆì •ì¼ì, íƒë°°ì‚¬ ê¸°ë³¸ê°’
    data = {
        "ë²ˆí˜¸": pick("ë²ˆí˜¸"),
        "ë¬¶ìŒë°°ì†¡ë²ˆí˜¸": pick("ë¬¶ìŒë°°ì†¡ë²ˆí˜¸"),
        "ì£¼ë¬¸ë²ˆí˜¸": pick("ì£¼ë¬¸ë²ˆí˜¸").apply(normalize_number),
        "íƒë°°ì‚¬": "CJëŒ€í•œí†µìš´",
        # CJ ì ‘ìˆ˜ ìƒì„¸ë‚´ì—­ì˜ ìš´ì†¡ì¥ë²ˆí˜¸ë¥¼ ìš°ì„  ì‚¬ìš© (ì •ê·œí™” í¬í•¨)
        "ìš´ì†¡ì¥ë²ˆí˜¸": merged["__ìš´ì†¡ì¥ë²ˆí˜¸"],
        "ë¶„ë¦¬ë°°ì†¡ Y/N": pick("ë¶„ë¦¬ë°°ì†¡ Y/N"),
        "ë¶„ë¦¬ë°°ì†¡ ì¶œê³ ì˜ˆì •ì¼": pick("ë¶„ë¦¬ë°°ì†¡ ì¶œê³ ì˜ˆì •ì¼"),
        "ì£¼ë¬¸ì‹œ ì¶œê³ ì˜ˆì •ì¼": pick("ì£¼ë¬¸ì‹œ ì¶œê³ ì˜ˆì •ì¼"),
        "ì¶œê³ ì¼(ë°œì†¡ì¼)": pick("ì§‘í™”ì˜ˆì •ì¼ì"),
        "ì£¼ë¬¸ì¼": pick("ì£¼ë¬¸ì¼"),
        "ë“±ë¡ìƒí’ˆëª…": pick("ë“±ë¡ìƒí’ˆëª…"),
        "ë“±ë¡ì˜µì…˜ëª…": pick("ë“±ë¡ì˜µì…˜ëª…"),
        "ë…¸ì¶œìƒí’ˆëª…(ì˜µì…˜ëª…)": pick("ë…¸ì¶œìƒí’ˆëª…(ì˜µì…˜ëª…)"),
        "ë…¸ì¶œìƒí’ˆID": pick("ë…¸ì¶œìƒí’ˆID"),
        "ì˜µì…˜ID": pick("ì˜µì…˜ID"),
        "ìµœì´ˆë“±ë¡ì˜µì…˜ëª…": pick("ìµœì´ˆë“±ë¡ì˜µì…˜ëª…") if "ìµœì´ˆë“±ë¡ì˜µì…˜ëª…" in merged else pick("ìµœì´ˆë“±ë¡ë“±ë¡ìƒí’ˆëª…/ì˜µì…˜ëª…"),
        "ì—…ì²´ìƒí’ˆì½”ë“œ": pick("ì—…ì²´ìƒí’ˆì½”ë“œ"),
        "ë°”ì½”ë“œ": pick("ë°”ì½”ë“œ"),
        "ê²°ì œì•¡": pick("ê²°ì œì•¡"),
        "ë°°ì†¡ë¹„êµ¬ë¶„": pick("ë°°ì†¡ë¹„êµ¬ë¶„"),
        "ë°°ì†¡ë¹„": pick("ë°°ì†¡ë¹„"),
        "ë„ì„œì‚°ê°„ ì¶”ê°€ë°°ì†¡ë¹„": pick("ë„ì„œì‚°ê°„ ì¶”ê°€ë°°ì†¡ë¹„"),
        "êµ¬ë§¤ìˆ˜(ìˆ˜ëŸ‰)": pick("êµ¬ë§¤ìˆ˜(ìˆ˜ëŸ‰)"),
        "ì˜µì…˜íŒë§¤ê°€(íŒë§¤ë‹¨ê°€)": pick("ì˜µì…˜íŒë§¤ê°€(íŒë§¤ë‹¨ê°€)"),
        "êµ¬ë§¤ì": pick("êµ¬ë§¤ì"),
        "êµ¬ë§¤ìì „í™”ë²ˆí˜¸": pick("êµ¬ë§¤ìì „í™”ë²ˆí˜¸"),
        "ìˆ˜ì·¨ì¸ì´ë¦„": pick("ìˆ˜ì·¨ì¸ì´ë¦„"),
        "ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸": pick("ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸"),
        "ìš°í¸ë²ˆí˜¸": pick("ìš°í¸ë²ˆí˜¸"),
        "ìˆ˜ì·¨ì¸ ì£¼ì†Œ": pick("ìˆ˜ì·¨ì¸ ì£¼ì†Œ"),
        "ë°°ì†¡ë©”ì„¸ì§€": pick("ë°°ì†¡ë©”ì„¸ì§€"),
        "ìƒí’ˆë³„ ì¶”ê°€ë©”ì‹œì§€": pick("ìƒí’ˆë³„ ì¶”ê°€ë©”ì‹œì§€"),
        "ì£¼ë¬¸ì ì¶”ê°€ë©”ì‹œì§€": pick("ì£¼ë¬¸ì ì¶”ê°€ë©”ì‹œì§€"),
        "ë°°ì†¡ì™„ë£Œì¼": pick("ë°°ì†¡ì™„ë£Œì¼"),
        "êµ¬ë§¤í™•ì •ì¼ì": pick("êµ¬ë§¤í™•ì •ì¼ì"),
        "ê°œì¸í†µê´€ë²ˆí˜¸(PCCC)": pick("ê°œì¸í†µê´€ë²ˆí˜¸(PCCC)"),
        "í†µê´€ìš©êµ¬ë§¤ìì „í™”ë²ˆí˜¸": pick("í†µê´€ìš©ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸") if "í†µê´€ìš©ìˆ˜ì·¨ì¸ì „í™”ë²ˆí˜¸" in merged else pick("í†µê´€ìš©êµ¬ë§¤ìì „í™”ë²ˆí˜¸"),
        "ê¸°íƒ€": pick("ê¸°íƒ€"),
        "ê²°ì œìœ„ì¹˜": pick("ê²°ì œìœ„ì¹˜"),
    }

    output = pd.DataFrame(data)
    # Ensure column order
    output = output[output_cols]
    return output


def render_coupang_bulk():
    st.markdown("**ì¿ íŒ¡ ë¡œìš°ë°ì´í„° + íŒŒì¼ì ‘ìˆ˜ ìƒì„¸ë‚´ì—­ ì—…ë¡œë“œ**")

    raw_file = st.file_uploader(
        "ì¿ íŒ¡ ë¡œìš°ë°ì´í„° (.xlsx)", type=["xlsx"], accept_multiple_files=False, key="raw_coupang_bulk"
    )
    cj_file = st.file_uploader(
        "íŒŒì¼ì ‘ìˆ˜ ìƒì„¸ë‚´ì—­ (.xlsx)", type=["xlsx"], accept_multiple_files=False, key="cj_bulk"
    )

    # Reset cached result if new uploads
    files_key = (
        raw_file.name if raw_file else None,
        cj_file.name if cj_file else None,
    )
    if files_key != st.session_state.last_bulk_names:
        st.session_state.coupang_bulk_result = None
        st.session_state.last_bulk_names = files_key

    if raw_file:
        df_raw = pd.read_excel(raw_file)
        st.caption("ë¡œìš°ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 5í–‰)")
        st.dataframe(df_raw.head(5), width="stretch")
    else:
        df_raw = None

    if cj_file:
        df_cj = pd.read_excel(cj_file)
        st.caption("íŒŒì¼ì ‘ìˆ˜ ìƒì„¸ë‚´ì—­ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 5í–‰)")
        st.dataframe(df_cj.head(5), width="stretch")
    else:
        df_cj = None

    if df_raw is not None and df_cj is not None:
        if st.button("ì‘ì—… ì‹¤í–‰", type="primary"):
            try:
                result_df = build_coupang_bulk(df_raw, df_cj)
                match_count = (
                    result_df["ìš´ì†¡ì¥ë²ˆí˜¸"].fillna("").astype(str).str.strip().ne("").sum()
                )
                total = len(result_df)
                if match_count == 0:
                    st.warning("ì£¼ë¬¸ë²ˆí˜¸ ë§¤ì¹­ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. ë‘ íŒŒì¼ì˜ ì£¼ë¬¸ë²ˆí˜¸/ê³ ê°ì£¼ë¬¸ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    st.session_state.coupang_bulk_result = None
                    return

                buf = io.BytesIO()
                result_df.to_excel(buf, index=False)
                buf.seek(0)
                filename = f"ì¿ íŒ¡_ëŒ€ëŸ‰ë“±ë¡_{dt.datetime.now():%y%m%d}.xlsx"
                st.session_state.coupang_bulk_result = {
                    "df": result_df,
                    "data": buf.getvalue(),
                    "name": filename,
                    "match": match_count,
                    "total": total,
                }
                st.success(f"ì‘ì—… ì™„ë£Œ: {filename} (ìš´ì†¡ì¥ ë§¤ì¹­ {match_count}/{total})")
            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    result = st.session_state.get("coupang_bulk_result")
    if result:
        st.markdown("---")
        st.markdown("**ì‘ì—… ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10í–‰)**")
        st.dataframe(result["df"].head(10), width="stretch")
        match = result.get("match")
        total = result.get("total")
        if match is not None and total is not None:
            st.caption(f"ìš´ì†¡ì¥ë²ˆí˜¸ ë§¤ì¹­ ê²°ê³¼: {match}/{total}")
        st.download_button(
            "ë‹¤ìš´ë¡œë“œ: ì¿ íŒ¡ ëŒ€ëŸ‰ë“±ë¡",
            data=result["data"],
            file_name=result["name"],
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary",
        )


def render_settings():
    """ì„¤ì • í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.markdown("### âš™ï¸ ì„¤ì •")
    st.caption("OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì—¬ ì±—ë´‡ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # í˜„ì¬ ì €ì¥ëœ API í‚¤ ë¡œë“œ
    current_api_key = get_openai_api_key()

    # API í‚¤ í‘œì‹œ (ë§ˆìŠ¤í‚¹)
    if current_api_key:
        masked_key = current_api_key[:8] + "*" * (len(current_api_key) - 12) + current_api_key[-4:] if len(current_api_key) > 12 else "****"
        st.info(f"í˜„ì¬ ì €ì¥ëœ API í‚¤: `{masked_key}`")
    else:
        st.warning("ì €ì¥ëœ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("#### OpenAI API í‚¤ ì…ë ¥")

    # API í‚¤ ì…ë ¥ í¼
    with st.form("api_key_form"):
        new_api_key = st.text_input(
            "API í‚¤",
            value="",
            type="password",
            placeholder="sk-...",
            help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. API í‚¤ëŠ” ì•”í˜¸í™”ë˜ì–´ ë¡œì»¬ì— ì €ì¥ë©ë‹ˆë‹¤."
        )

        col1, col2 = st.columns([1, 4])
        with col1:
            submit = st.form_submit_button("ì €ì¥", type="primary", use_container_width=True)
        with col2:
            clear = st.form_submit_button("ì‚­ì œ", use_container_width=True)

        if submit:
            if new_api_key.strip():
                if save_openai_api_key(new_api_key.strip()):
                    st.success("âœ… API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
            else:
                st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        if clear:
            if save_openai_api_key(""):
                st.success("âœ… API í‚¤ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

    st.markdown("---")
    st.markdown("#### ğŸ¤– API ì—°ë™ í…ŒìŠ¤íŠ¸")

    # API í‚¤ê°€ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if current_api_key:
        st.caption("ì €ì¥ëœ API í‚¤ë¡œ ê°„ë‹¨í•œ ì±„íŒ…ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")

        # ì±„íŒ… í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ
        with st.container():
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
            if st.session_state.chat_history:
                st.markdown("**ì±„íŒ… ê¸°ë¡:**")
                for chat in st.session_state.chat_history:
                    if chat["role"] == "user":
                        st.markdown(f"**ğŸ‘¤ You:** {chat['content']}")
                    else:
                        st.markdown(f"**ğŸ¤– AI:** {chat['content']}")
                st.markdown("---")

            # ì±„íŒ… ì…ë ¥ í¼
            with st.form(key="chat_form", clear_on_submit=True):
                col1, col2 = st.columns([5, 1])
                with col1:
                    user_input = st.text_input("ë©”ì‹œì§€", placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", label_visibility="collapsed")
                with col2:
                    submit = st.form_submit_button("ì „ì†¡", use_container_width=True, type="primary")

                if submit and user_input.strip():
                    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                    st.session_state.chat_history.append({"role": "user", "content": user_input.strip()})

                    # API í˜¸ì¶œ
                    with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                        result = test_openai_api(current_api_key, user_input.strip())

                    if result["success"]:
                        # AI ì‘ë‹µ ì¶”ê°€
                        st.session_state.chat_history.append({"role": "assistant", "content": result["message"]})
                    else:
                        # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
                        st.session_state.chat_history.append({"role": "assistant", "content": f"âŒ {result['message']}"})

                    st.rerun()

            # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ë²„íŠ¼
            if st.session_state.chat_history:
                if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=False):
                    st.session_state.chat_history = []
                    st.rerun()
    else:
        st.info("API í‚¤ë¥¼ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")

    st.markdown("---")
    st.markdown("#### API í‚¤ ë°œê¸‰ ì•ˆë‚´")
    st.markdown("""
    1. [OpenAI í”Œë«í¼](https://platform.openai.com/api-keys)ì— ë¡œê·¸ì¸
    2. API Keys ë©”ë‰´ì—ì„œ 'Create new secret key' í´ë¦­
    3. ìƒì„±ëœ í‚¤ë¥¼ ë³µì‚¬í•˜ì—¬ ìœ„ì— ì…ë ¥
    """)

    st.markdown("---")
    if st.button("â† ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=False):
        st.session_state.show_settings = False
        st.rerun()


# ì„¤ì • í˜ì´ì§€ì™€ ë©”ì¸ í˜ì´ì§€ ë¶„ê¸°
if st.session_state.show_settings:
    render_settings()
else:
    # ë©”ì¸ í˜ì´ì§€ ë Œë”ë§
    if st.session_state.step == "landing":
        section_heading("ë¬´ì—‡ì„ í•˜ì‹œê² ì–´ìš”?")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸšš CJ ë°œì£¼ì„œ ë§Œë“¤ê¸°", use_container_width=True, type="secondary"):
                go("channel", job="cj")

        with col2:
            if st.button("ğŸ“‘ ëŒ€ëŸ‰ë“±ë¡ íŒŒì¼ ë§Œë“¤ê¸°", use_container_width=True, type="secondary"):
                go("channel", job="bulk")

    elif st.session_state.step == "channel":
        section_heading(
            "ì±„ë„ì„ ì„ íƒí•˜ì„¸ìš”",
            f"ì„ íƒ ì‘ì—…: {'CJ ë°œì£¼ì„œ' if st.session_state.job == 'cj' else 'ëŒ€ëŸ‰ë“±ë¡ íŒŒì¼'}",
        )

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸŸ¢ ë„¤ì´ë²„", use_container_width=True, type="secondary"):
                go("form", channel="naver")

        with col2:
            if st.button("ğŸŸ  ì¿ íŒ¡", use_container_width=True, type="secondary"):
                go("form", channel="coupang")

        st.button("â† ì²˜ìŒìœ¼ë¡œ", on_click=reset)

    elif st.session_state.step == "form":
        section_heading(
            f"{'CJ ë°œì£¼ì„œ' if st.session_state.job == 'cj' else 'ëŒ€ëŸ‰ë“±ë¡ íŒŒì¼'} Â· "
            f"{st.session_state.channel.upper()}",
            None,
        )

        if st.session_state.job == "cj" and st.session_state.channel == "coupang":
            render_coupang_cj()
        elif st.session_state.job == "cj" and st.session_state.channel == "naver":
            render_naver_cj()
        elif st.session_state.job == "bulk" and st.session_state.channel == "coupang":
            render_coupang_bulk()
        else:
            st.info("ì´ ì±„ë„/ì‘ì—… ì¡°í•©ì— ëŒ€í•œ í¼ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        st.button("â† ì±„ë„ ì„ íƒìœ¼ë¡œ", on_click=lambda: st.session_state.update({"step": "channel"}))
